{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb95a300",
   "metadata": {},
   "source": [
    "# Timing Curves (Event Probabilities)\n",
    "\n",
    "Fit timing probabilities for draw/rep/recallable events by Strategy×Grade×AgeBucket\n",
    "with fallback tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fabb6142",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-31T06:30:06.806768Z",
     "iopub.status.busy": "2026-01-31T06:30:06.806188Z",
     "iopub.status.idle": "2026-01-31T06:30:07.832927Z",
     "shell.execute_reply": "2026-01-31T06:30:07.830737Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88ef9718",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-31T06:30:07.838556Z",
     "iopub.status.busy": "2026-01-31T06:30:07.837820Z",
     "iopub.status.idle": "2026-01-31T06:30:07.913018Z",
     "shell.execute_reply": "2026-01-31T06:30:07.909899Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using INPUT_PATH: /Users/mozeramozali/Desktop/Equity-Cashflow-projection/anonymized.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "RUN_TAG = os.environ.get(\"RUN_TAG\")\n",
    "HIST_END = os.environ.get(\"HIST_END\")\n",
    "if RUN_TAG is None:\n",
    "    RUN_TAG = HIST_END or \"2025Q3\"\n",
    "BASE_OUT = Path(\"model_fits\") / \"runs\" / RUN_TAG\n",
    "CALIB_DIR = BASE_OUT / \"calibration\"\n",
    "PROJ_DIR = BASE_OUT / \"projection\"\n",
    "\n",
    "INPUT_PATH = \"anonymized.csv\"\n",
    "OUT_DIR = str(CALIB_DIR)\n",
    "MIN_OBS_AGE = 150\n",
    "MIN_OBS_SG = 200\n",
    "MIN_OBS_S = 300\n",
    "\n",
    "if not Path(INPUT_PATH).exists():\n",
    "    candidates = list(Path.cwd().glob(\"**/anonymized.csv\"))\n",
    "    if not candidates:\n",
    "        candidates = list(Path.cwd().parent.glob(\"**/anonymized.csv\"))\n",
    "    if not candidates:\n",
    "        candidates = list(Path.cwd().parent.parent.glob(\"**/anonymized.csv\"))\n",
    "    if candidates:\n",
    "        INPUT_PATH = str(candidates[0])\n",
    "    else:\n",
    "        raise FileNotFoundError(\"anonymized.csv not found. Set INPUT_PATH to the full path.\")\n",
    "\n",
    "print(\"Using INPUT_PATH:\", INPUT_PATH)\n",
    "Path(OUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "Path(CALIB_DIR).mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0af1abb4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-31T06:30:07.918321Z",
     "iopub.status.busy": "2026-01-31T06:30:07.917781Z",
     "iopub.status.idle": "2026-01-31T06:30:08.007374Z",
     "shell.execute_reply": "2026-01-31T06:30:08.002807Z"
    }
   },
   "outputs": [],
   "source": [
    "AGE_BINS_Q = [-1, 3, 7, 11, 15, 19, 1000]\n",
    "AGE_LABELS = [\"0-3\", \"4-7\", \"8-11\", \"12-15\", \"16-19\", \"20+\"]\n",
    "\n",
    "\n",
    "def _norm_key(s: str) -> str:\n",
    "    return \" \".join(s.strip().lower().replace(\"_\", \" \").split())\n",
    "\n",
    "\n",
    "def normalize_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    col_map = {_norm_key(c): c for c in df.columns}\n",
    "    def _get(name: str) -> str:\n",
    "        k = _norm_key(name)\n",
    "        return col_map.get(k, name)\n",
    "\n",
    "    rename = {}\n",
    "    rename[_get(\"Adj strategy\")] = \"Adj Strategy\"\n",
    "    rename[_get(\"Adj Strategy\")] = \"Adj Strategy\"\n",
    "    rename[_get(\"Quarter of Transaction Date\")] = \"Quarter\"\n",
    "    rename[_get(\"Year of Transaction Date\")] = \"Year\"\n",
    "    rename[_get(\"FundID\")] = \"FundID\"\n",
    "    rename[_get(\"Grade\")] = \"Grade\"\n",
    "    rename[_get(\"Current Grade\")] = \"Grade_Current\"\n",
    "    rename[_get(\"CurrentGrade\")] = \"Grade_Current\"\n",
    "    rename[_get(\"Grade Current\")] = \"Grade_Current\"\n",
    "    rename[_get(\"Grade_Current\")] = \"Grade_Current\"\n",
    "    rename[_get(\"Adj Drawdown EUR\")] = \"Adj Drawdown EUR\"\n",
    "    rename[_get(\"Adj Repayment EUR\")] = \"Adj Repayment EUR\"\n",
    "    rename[_get(\"Recallable\")] = \"Recallable\"\n",
    "    rename[_get(\"Fund_Age_Quarters\")] = \"Fund_Age_Quarters\"\n",
    "    return df.rename(columns=rename)\n",
    "\n",
    "\n",
    "def parse_quarter(q) -> float:\n",
    "    if pd.isna(q):\n",
    "        return np.nan\n",
    "    if isinstance(q, (int, np.integer, float, np.floating)):\n",
    "        return float(q)\n",
    "    s = str(q).strip().upper()\n",
    "    if s.startswith(\"Q\"):\n",
    "        s = s[1:]\n",
    "    try:\n",
    "        return float(s)\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def add_quarter_end(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df[\"Quarter\"] = df[\"Quarter\"].apply(parse_quarter)\n",
    "    df[\"Year\"] = pd.to_numeric(df[\"Year\"], errors=\"coerce\")\n",
    "    m = df[\"Year\"].notna() & df[\"Quarter\"].notna()\n",
    "    years = df.loc[m, \"Year\"].astype(int)\n",
    "    quarters = df.loc[m, \"Quarter\"].astype(int)\n",
    "    df.loc[m, \"quarter_end\"] = pd.PeriodIndex(year=years, quarter=quarters, freq=\"Q\").to_timestamp(\"Q\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def apply_current_grade(df: pd.DataFrame, context: str = \"\") -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "\n",
    "    if \"Grade\" in df.columns and \"Grade_Seed\" not in df.columns:\n",
    "        df[\"Grade_Seed\"] = df[\"Grade\"]\n",
    "\n",
    "    if \"Grade\" in df.columns:\n",
    "        df[\"Grade\"] = df[\"Grade\"].astype(str).str.strip()\n",
    "        df.loc[df[\"Grade\"].isin([\"\", \"nan\", \"None\", \"NaN\", \"<NA>\"]), \"Grade\"] = np.nan\n",
    "\n",
    "    if \"quarter_end\" not in df.columns:\n",
    "        df = add_quarter_end(df)\n",
    "\n",
    "    df[\"QPeriod\"] = df[\"quarter_end\"].dt.to_period(\"Q\")\n",
    "\n",
    "    cols = [\n",
    "        \"FundID\",\n",
    "        \"Adj Strategy\",\n",
    "        \"QPeriod\",\n",
    "        \"quarter_end\",\n",
    "        \"Adj Drawdown EUR\",\n",
    "        \"Adj Repayment EUR\",\n",
    "        \"NAV Adjusted EUR\",\n",
    "        \"First Closing Date\",\n",
    "        \"Grade\",\n",
    "    ]\n",
    "    cols = [c for c in cols if c in df.columns]\n",
    "    cash = df[cols].copy()\n",
    "    cash = cash.rename(\n",
    "        columns={\n",
    "            \"Adj Strategy\": \"AdjStrategy\",\n",
    "            \"quarter_end\": \"TransactionDate\",\n",
    "            \"First Closing Date\": \"FirstClosingDate\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    cash[\"TransactionDate\"] = pd.to_datetime(cash[\"TransactionDate\"], errors=\"coerce\")\n",
    "    if \"FirstClosingDate\" in cash.columns:\n",
    "        cash[\"FirstClosingDate\"] = pd.to_datetime(cash[\"FirstClosingDate\"], errors=\"coerce\")\n",
    "    else:\n",
    "        cash[\"FirstClosingDate\"] = pd.NaT\n",
    "\n",
    "    for c in [\"Adj Drawdown EUR\", \"Adj Repayment EUR\", \"NAV Adjusted EUR\"]:\n",
    "        if c in cash.columns:\n",
    "            cash[c] = pd.to_numeric(cash[c], errors=\"coerce\").fillna(0.0)\n",
    "        else:\n",
    "            cash[c] = 0.0\n",
    "\n",
    "    cash = cash.dropna(subset=[\"FundID\", \"TransactionDate\"])\n",
    "\n",
    "    if cash[\"FirstClosingDate\"].isna().any():\n",
    "        first_tx = cash.groupby(\"FundID\")[\"TransactionDate\"].transform(\"min\")\n",
    "        cash[\"FirstClosingDate\"] = cash[\"FirstClosingDate\"].fillna(first_tx)\n",
    "\n",
    "    if cash.empty:\n",
    "        return df\n",
    "\n",
    "    fund_strategy = (\n",
    "        cash.groupby(\"FundID\")[\"AdjStrategy\"]\n",
    "        .agg(lambda s: s.mode().iat[0] if len(s.mode()) else s.iloc[0])\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    q_snap = (\n",
    "        cash.sort_values([\"FundID\", \"TransactionDate\"])\n",
    "        .groupby([\"FundID\", \"QPeriod\"], as_index=False)\n",
    "        .agg(\n",
    "            AdjStrategy=(\"AdjStrategy\", \"last\"),\n",
    "            FirstClosingDate=(\"FirstClosingDate\", \"last\"),\n",
    "            QuarterDrawdown=(\"Adj Drawdown EUR\", \"sum\"),\n",
    "            QuarterRepayment=(\"Adj Repayment EUR\", \"sum\"),\n",
    "            QuarterEndNAV=(\"NAV Adjusted EUR\", \"last\"),\n",
    "            QuarterEndDate=(\"TransactionDate\", \"max\"),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    q_snap = q_snap.sort_values([\"FundID\", \"QPeriod\"])\n",
    "    q_snap[\"QuarterEndNAV\"] = q_snap.groupby(\"FundID\")[\"QuarterEndNAV\"].ffill().fillna(0)\n",
    "\n",
    "    q_snap[\"CumDrawdown\"] = q_snap.groupby(\"FundID\")[\"QuarterDrawdown\"].cumsum()\n",
    "    q_snap[\"CumRepayment\"] = q_snap.groupby(\"FundID\")[\"QuarterRepayment\"].cumsum()\n",
    "    q_snap[\"PaidIn\"] = q_snap[\"CumDrawdown\"].abs()\n",
    "    q_snap[\"Distributed\"] = q_snap[\"CumRepayment\"].abs()\n",
    "    q_snap[\"NAV\"] = q_snap[\"QuarterEndNAV\"].abs()\n",
    "\n",
    "    q_snap[\"DPI\"] = np.where(q_snap[\"PaidIn\"] > 0, q_snap[\"Distributed\"] / q_snap[\"PaidIn\"], np.nan)\n",
    "    q_snap[\"TVPI\"] = np.where(\n",
    "        q_snap[\"PaidIn\"] > 0,\n",
    "        (q_snap[\"Distributed\"] + q_snap[\"NAV\"]) / q_snap[\"PaidIn\"],\n",
    "        np.nan,\n",
    "    )\n",
    "\n",
    "    def xnpv(rate, cfs, dts):\n",
    "        dts = np.asarray(dts, dtype=\"datetime64[ns]\")\n",
    "        cfs = np.asarray(cfs, dtype=float)\n",
    "        t0 = dts[0]\n",
    "        day_counts = (dts - t0) / np.timedelta64(1, \"D\")\n",
    "        years = day_counts / 365.0\n",
    "        return np.sum(cfs / ((1.0 + rate) ** years))\n",
    "\n",
    "    def xirr_newton(cfs, dts, guess=0.1, max_iter=80, tol=1e-7):\n",
    "        dts = np.asarray(dts, dtype=\"datetime64[ns]\")\n",
    "        cfs = np.asarray(cfs, dtype=float)\n",
    "        rate = float(guess)\n",
    "        for _ in range(max_iter):\n",
    "            f = xnpv(rate, cfs, dts)\n",
    "            if not np.isfinite(f):\n",
    "                return np.nan\n",
    "            if abs(f) < tol:\n",
    "                return rate\n",
    "            eps = 1e-6\n",
    "            f1 = xnpv(rate + eps, cfs, dts)\n",
    "            df = (f1 - f) / eps\n",
    "            if df == 0 or not np.isfinite(df):\n",
    "                return np.nan\n",
    "            rate_new = rate - f / df\n",
    "            if rate_new <= -0.999999 or not np.isfinite(rate_new):\n",
    "                return np.nan\n",
    "            rate = rate_new\n",
    "        return np.nan\n",
    "\n",
    "    def compute_fund_quarter_xirr(fund_cash, fund_q):\n",
    "        fund_cash = fund_cash.sort_values(\"TransactionDate\")\n",
    "        cfs = (-fund_cash[\"Adj Drawdown EUR\"].abs() + fund_cash[\"Adj Repayment EUR\"].abs()).to_numpy(dtype=float)\n",
    "        dts = fund_cash[\"TransactionDate\"].to_numpy(dtype=\"datetime64[ns]\")\n",
    "        irr_vals = []\n",
    "        irr_flags = []\n",
    "        j = 0\n",
    "        n = len(cfs)\n",
    "        for r in fund_q.itertuples(index=False):\n",
    "            q_end = np.datetime64(r.QuarterEndDate, \"ns\")\n",
    "            while j < n and dts[j] <= q_end:\n",
    "                j += 1\n",
    "            cfs_slice = cfs[:j]\n",
    "            dts_slice = dts[:j]\n",
    "            if len(cfs_slice) == 0:\n",
    "                irr_vals.append(np.nan)\n",
    "                irr_flags.append(\"no_txns\")\n",
    "                continue\n",
    "            terminal_nav = float(abs(r.NAV)) if np.isfinite(r.NAV) else 0.0\n",
    "            cfs_full = np.append(cfs_slice, terminal_nav)\n",
    "            dts_full = np.append(dts_slice, q_end).astype(\"datetime64[ns]\")\n",
    "            if not (np.any(cfs_full < 0) and np.any(cfs_full > 0)):\n",
    "                irr_vals.append(np.nan)\n",
    "                irr_flags.append(\"no_sign_change\")\n",
    "                continue\n",
    "            tvpi = r.TVPI\n",
    "            guess = 0.10 if (pd.notna(tvpi) and tvpi > 1.0) else -0.10\n",
    "            irr = xirr_newton(cfs_full, dts_full, guess=guess)\n",
    "            if pd.notna(tvpi) and (0.98 <= tvpi <= 1.02):\n",
    "                if not np.isfinite(irr):\n",
    "                    irr2 = xirr_newton(cfs_full, dts_full, guess=-guess)\n",
    "                    if np.isfinite(irr2):\n",
    "                        irr = irr2\n",
    "                        irr_flags.append(\"flat_retry_success\")\n",
    "                    else:\n",
    "                        irr = 0.0\n",
    "                        irr_flags.append(\"flat_to_zero\")\n",
    "                else:\n",
    "                    irr_flags.append(\"flat_success\")\n",
    "            else:\n",
    "                irr_flags.append(\"ok\" if np.isfinite(irr) else \"fail\")\n",
    "            irr_vals.append(irr)\n",
    "        return pd.DataFrame({\"IRR\": irr_vals, \"IRR_Flag\": irr_flags})\n",
    "\n",
    "    irr_rows = []\n",
    "    for fund_id, fund_q in q_snap.groupby(\"FundID\", sort=False):\n",
    "        fund_cash = cash[cash[\"FundID\"] == fund_id]\n",
    "        irr_df = compute_fund_quarter_xirr(fund_cash, fund_q)\n",
    "        irr_df = irr_df.copy()\n",
    "        irr_df[\"FundID\"] = fund_id\n",
    "        irr_df[\"QPeriod\"] = fund_q[\"QPeriod\"].values\n",
    "        irr_rows.append(irr_df)\n",
    "\n",
    "    if irr_rows:\n",
    "        irr_all = pd.concat(irr_rows, ignore_index=True)\n",
    "        q_snap = q_snap.merge(irr_all, on=[\"FundID\", \"QPeriod\"], how=\"left\")\n",
    "    else:\n",
    "        q_snap[\"IRR\"] = np.nan\n",
    "\n",
    "    def quartile_to_grade(s):\n",
    "        r = s.rank(pct=True)\n",
    "        return pd.cut(r, [0, 0.25, 0.5, 0.75, 1], labels=[\"D\", \"C\", \"B\", \"A\"], include_lowest=True)\n",
    "\n",
    "    q_snap[\"Grade_DPI\"] = q_snap.groupby([\"AdjStrategy\", \"QPeriod\"])[\"DPI\"].transform(quartile_to_grade)\n",
    "    q_snap[\"Grade_TVPI\"] = q_snap.groupby([\"AdjStrategy\", \"QPeriod\"])[\"TVPI\"].transform(quartile_to_grade)\n",
    "    q_snap[\"Grade_IRR\"] = q_snap.groupby([\"AdjStrategy\", \"QPeriod\"])[\"IRR\"].transform(quartile_to_grade)\n",
    "\n",
    "    DEBT_STRATEGIES = {\"Hybrid Debt-Equity\", \"Private Debt\", \"Other Private Debt\"}\n",
    "    VC_STRATEGY = \"Venture Capital\"\n",
    "\n",
    "    rep = cash[cash[\"Adj Repayment EUR\"].abs() > 0].copy()\n",
    "    first_repay = rep.groupby(\"FundID\")[\"TransactionDate\"].min().reset_index(name=\"FirstRepaymentDate\")\n",
    "    first_close = cash.groupby(\"FundID\")[\"FirstClosingDate\"].min().reset_index(name=\"FirstCloseDate\")\n",
    "    fund_timing = first_close.merge(first_repay, on=\"FundID\", how=\"left\")\n",
    "    fund_timing = fund_timing.merge(fund_strategy, on=\"FundID\", how=\"left\")\n",
    "    fund_timing[\"RepayWithin5Y\"] = (\n",
    "        fund_timing[\"FirstRepaymentDate\"].notna()\n",
    "        & (fund_timing[\"FirstRepaymentDate\"] <= (fund_timing[\"FirstCloseDate\"] + pd.DateOffset(years=5)))\n",
    "    )\n",
    "    fund_timing[\"BaseYears\"] = np.where(fund_timing[\"RepayWithin5Y\"], 5, 6)\n",
    "    fund_timing[\"InvestPeriodYears\"] = fund_timing[\"BaseYears\"] + 1\n",
    "\n",
    "    q_snap = q_snap.merge(\n",
    "        fund_timing[[\"FundID\", \"FirstCloseDate\", \"InvestPeriodYears\", \"AdjStrategy\"]],\n",
    "        on=[\"FundID\", \"AdjStrategy\"],\n",
    "        how=\"left\",\n",
    "    )\n",
    "    q_snap[\"IsInvestmentPeriod\"] = q_snap[\"QuarterEndDate\"] <= (\n",
    "        q_snap[\"FirstCloseDate\"] + q_snap[\"InvestPeriodYears\"].apply(lambda y: pd.DateOffset(years=int(y)))\n",
    "    )\n",
    "\n",
    "    fund_counts = (\n",
    "        q_snap.groupby([\"AdjStrategy\", \"QPeriod\"])[\"FundID\"].nunique().rename(\"StrategyFundCount\").reset_index()\n",
    "    )\n",
    "    q_snap = q_snap.merge(fund_counts, on=[\"AdjStrategy\", \"QPeriod\"], how=\"left\")\n",
    "\n",
    "    q_snap[\"IsDebt\"] = q_snap[\"AdjStrategy\"].isin(DEBT_STRATEGIES)\n",
    "    q_snap[\"IsVC\"] = q_snap[\"AdjStrategy\"].eq(VC_STRATEGY)\n",
    "\n",
    "    grade_to_idx = {\"A\": 0, \"B\": 1, \"C\": 2, \"D\": 3}\n",
    "    idx_to_grade = {0: \"A\", 1: \"B\", 2: \"C\", 3: \"D\"}\n",
    "\n",
    "    def worse_grade(g1, g2):\n",
    "        if pd.isna(g1):\n",
    "            return g2\n",
    "        if pd.isna(g2):\n",
    "            return g1\n",
    "        return g1 if grade_to_idx[g1] >= grade_to_idx[g2] else g2\n",
    "\n",
    "    def downgrade_one_notch(g):\n",
    "        if pd.isna(g):\n",
    "            return g\n",
    "        return idx_to_grade[min(grade_to_idx[g] + 1, 3)]\n",
    "\n",
    "    def final_grade(row):\n",
    "        if row[\"StrategyFundCount\"] < 30:\n",
    "            return worse_grade(row[\"Grade_DPI\"], row[\"Grade_TVPI\"])\n",
    "        if row[\"IsDebt\"]:\n",
    "            return row[\"Grade_IRR\"]\n",
    "        if row[\"IsInvestmentPeriod\"]:\n",
    "            return row[\"Grade_TVPI\"] if row[\"IsVC\"] else row[\"Grade_DPI\"]\n",
    "        base = row[\"Grade_IRR\"]\n",
    "        dpi_g = row[\"Grade_DPI\"]\n",
    "        if pd.isna(base):\n",
    "            return base\n",
    "        if pd.notna(dpi_g) and (grade_to_idx[dpi_g] > grade_to_idx[base]):\n",
    "            return downgrade_one_notch(base)\n",
    "        return base\n",
    "\n",
    "    q_snap[\"CurrentGrade\"] = q_snap.apply(final_grade, axis=1)\n",
    "\n",
    "    fund_quarters = cash[[\"FundID\", \"QPeriod\"]].drop_duplicates().sort_values([\"FundID\", \"QPeriod\"])\n",
    "    fund_quarters[\"RankQ\"] = fund_quarters.groupby(\"FundID\").cumcount() + 1\n",
    "    fund_quarters[\"Block4\"] = (fund_quarters[\"RankQ\"] - 1) // 4 + 1\n",
    "\n",
    "    fund_first = (\n",
    "        cash.dropna(subset=[\"Grade\"]).groupby(\"FundID\", as_index=False).first()[[\"FundID\", \"Grade\"]]\n",
    "        .rename(columns={\"Grade\": \"FirstGrade\"})\n",
    "    )\n",
    "\n",
    "    fund_quarters = fund_quarters.merge(fund_first, on=\"FundID\", how=\"left\")\n",
    "    fund_quarters = fund_quarters.merge(\n",
    "        q_snap[[\"FundID\", \"QPeriod\", \"CurrentGrade\"]], on=[\"FundID\", \"QPeriod\"], how=\"left\"\n",
    "    )\n",
    "\n",
    "    fund_quarters[\"AssignedGrade\"] = np.where(\n",
    "        (fund_quarters[\"Block4\"] == 1) & fund_quarters[\"FirstGrade\"].notna(),\n",
    "        fund_quarters[\"FirstGrade\"],\n",
    "        fund_quarters[\"CurrentGrade\"],\n",
    "    )\n",
    "\n",
    "    fund_quarters[\"AssignedGrade\"] = fund_quarters.groupby(\"FundID\")[\"AssignedGrade\"].ffill()\n",
    "\n",
    "    df = df.merge(fund_quarters[[\"FundID\", \"QPeriod\", \"AssignedGrade\"]], on=[\"FundID\", \"QPeriod\"], how=\"left\")\n",
    "    df[\"Grade_Current\"] = df[\"AssignedGrade\"]\n",
    "    if \"Grade_Seed\" in df.columns:\n",
    "        df[\"Grade_Current\"] = df[\"Grade_Current\"].fillna(df[\"Grade_Seed\"])\n",
    "    df[\"Grade\"] = df[\"Grade_Current\"]\n",
    "\n",
    "    if context:\n",
    "        print(f\"Computed Grade_Current using performance rules for {context}.\")\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "083c2c75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-31T06:30:08.016443Z",
     "iopub.status.busy": "2026-01-31T06:30:08.015282Z",
     "iopub.status.idle": "2026-01-31T06:30:40.827201Z",
     "shell.execute_reply": "2026-01-31T06:30:40.825840Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w3/y0xpfndx1099qx0947v35sxh0000gn/T/ipykernel_80567/2390645469.py:54: FutureWarning: Constructing PeriodIndex from fields is deprecated. Use PeriodIndex.from_fields instead.\n",
      "  df.loc[m, \"quarter_end\"] = pd.PeriodIndex(year=years, quarter=quarters, freq=\"Q\").to_timestamp(\"Q\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w3/y0xpfndx1099qx0947v35sxh0000gn/T/ipykernel_80567/2390645469.py:267: PerformanceWarning: Adding/subtracting object-dtype array to DatetimeArray not vectorized.\n",
      "  q_snap[\"FirstCloseDate\"] + q_snap[\"InvestPeriodYears\"].apply(lambda y: pd.DateOffset(years=int(y)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed Grade_Current using performance rules for timing curves.\n",
      "Filtered history to <= 2025-09-30 (rows=30857)\n"
     ]
    }
   ],
   "source": [
    "# --- Load + compute ---\n",
    "\n",
    "df = pd.read_csv(INPUT_PATH, engine=\"python\")\n",
    "df = normalize_columns(df)\n",
    "df = add_quarter_end(df)\n",
    "df = apply_current_grade(df, context=\"timing curves\")\n",
    "\n",
    "# Age buckets\n",
    "if \"Fund_Age_Quarters\" in df.columns:\n",
    "    df[\"AgeBucket\"] = pd.cut(pd.to_numeric(df[\"Fund_Age_Quarters\"], errors=\"coerce\"),\n",
    "                             bins=AGE_BINS_Q, labels=AGE_LABELS)\n",
    "else:\n",
    "    df[\"AgeBucket\"] = \"ALL\"\n",
    "\n",
    "# Events\n",
    "\n",
    "df[\"draw_event\"] = pd.to_numeric(df[\"Adj Drawdown EUR\"], errors=\"coerce\").fillna(0.0) > 0\n",
    "\n",
    "df[\"rep_event\"] = pd.to_numeric(df[\"Adj Repayment EUR\"], errors=\"coerce\").fillna(0.0) > 0\n",
    "\n",
    "df[\"rc_event\"] = pd.to_numeric(df[\"Recallable\"], errors=\"coerce\").fillna(0.0) > 0\n",
    "# --- Optional historical cutoff ---\n",
    "HIST_END_QE = None\n",
    "if HIST_END:\n",
    "    try:\n",
    "        y = int(HIST_END[:4])\n",
    "        q = int(HIST_END[-1])\n",
    "        HIST_END_QE = pd.Period(f\"{y}Q{q}\", freq=\"Q\").to_timestamp(\"Q\")\n",
    "    except Exception:\n",
    "        HIST_END_QE = None\n",
    "if HIST_END_QE is not None:\n",
    "    df = df[df[\"quarter_end\"] <= HIST_END_QE].copy()\n",
    "    print(f\"Filtered history to <= {HIST_END_QE.date()} (rows={len(df)})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fdd4738",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-31T06:30:40.831410Z",
     "iopub.status.busy": "2026-01-31T06:30:40.830954Z",
     "iopub.status.idle": "2026-01-31T06:30:40.939907Z",
     "shell.execute_reply": "2026-01-31T06:30:40.937362Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w3/y0xpfndx1099qx0947v35sxh0000gn/T/ipykernel_80567/3689770901.py:5: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for gkey, g in df.groupby(cols):\n"
     ]
    }
   ],
   "source": [
    "# --- Fit levels ---\n",
    "\n",
    "def _fit_level(level_name: str, cols: list, min_obs: int):\n",
    "    rows = []\n",
    "    for gkey, g in df.groupby(cols):\n",
    "        if not isinstance(gkey, tuple):\n",
    "            gkey = (gkey,)\n",
    "        if len(g) < min_obs:\n",
    "            continue\n",
    "        n_obs = len(g)\n",
    "        n_draw = int(g[\"draw_event\"].sum())\n",
    "        n_rep = int(g[\"rep_event\"].sum())\n",
    "        n_rc = int(g[\"rc_event\"].sum())\n",
    "        p_draw = n_draw / n_obs if n_obs else 0.0\n",
    "        p_rep = n_rep / n_obs if n_obs else 0.0\n",
    "        p_rc = n_rc / n_rep if n_rep else 0.0\n",
    "        row = {\n",
    "            \"level\": level_name,\n",
    "            \"n_obs\": n_obs,\n",
    "            \"n_draw\": n_draw,\n",
    "            \"n_rep\": n_rep,\n",
    "            \"n_rc\": n_rc,\n",
    "            \"p_draw\": p_draw,\n",
    "            \"p_rep\": p_rep,\n",
    "            \"p_rc_given_rep\": p_rc,\n",
    "        }\n",
    "        for idx, col in enumerate(cols):\n",
    "            row[col] = gkey[idx]\n",
    "        rows.append(row)\n",
    "    return rows\n",
    "\n",
    "lvl_age = _fit_level(\"strategy_grade_age\", [\"Adj Strategy\", \"Grade\", \"AgeBucket\"], MIN_OBS_AGE)\n",
    "lvl_sg = _fit_level(\"strategy_grade\", [\"Adj Strategy\", \"Grade\"], MIN_OBS_SG)\n",
    "lvl_s = _fit_level(\"strategy\", [\"Adj Strategy\"], MIN_OBS_S)\n",
    "\n",
    "by_group = pd.DataFrame(lvl_age + lvl_sg + lvl_s)\n",
    "by_group.to_csv(Path(OUT_DIR) / \"timing_probs_by_group.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c44046fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-31T06:30:40.945071Z",
     "iopub.status.busy": "2026-01-31T06:30:40.944596Z",
     "iopub.status.idle": "2026-01-31T06:30:41.337271Z",
     "shell.execute_reply": "2026-01-31T06:30:41.335283Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: model_fits/runs/2025Q3/calibration/timing_probs_by_group.csv\n",
      "Wrote: model_fits/runs/2025Q3/calibration/timing_probs_selected.csv\n"
     ]
    }
   ],
   "source": [
    "# --- Selected with fallback ---\n",
    "\n",
    "base_groups = df[[\"Adj Strategy\", \"Grade\", \"AgeBucket\"]].dropna().drop_duplicates()\n",
    "selected_rows = []\n",
    "\n",
    "# global row\n",
    "n_obs = len(df)\n",
    "if n_obs:\n",
    "    n_draw = int(df[\"draw_event\"].sum())\n",
    "    n_rep = int(df[\"rep_event\"].sum())\n",
    "    n_rc = int(df[\"rc_event\"].sum())\n",
    "    global_row = {\n",
    "        \"level\": \"global\",\n",
    "        \"n_obs\": n_obs,\n",
    "        \"n_draw\": n_draw,\n",
    "        \"n_rep\": n_rep,\n",
    "        \"n_rc\": n_rc,\n",
    "        \"p_draw\": n_draw / n_obs if n_obs else 0.0,\n",
    "        \"p_rep\": n_rep / n_obs if n_obs else 0.0,\n",
    "        \"p_rc_given_rep\": n_rc / n_rep if n_rep else 0.0,\n",
    "    }\n",
    "else:\n",
    "    global_row = {}\n",
    "\n",
    "for _, r in base_groups.iterrows():\n",
    "    s, g, a = r[\"Adj Strategy\"], r[\"Grade\"], r[\"AgeBucket\"]\n",
    "    row = None\n",
    "    if not by_group.empty:\n",
    "        m = (by_group[\"level\"] == \"strategy_grade_age\") & (by_group[\"Adj Strategy\"] == s) & (by_group[\"Grade\"] == g) & (by_group[\"AgeBucket\"] == a)\n",
    "        if m.any():\n",
    "            row = by_group.loc[m].iloc[0].to_dict()\n",
    "    if row is None and not by_group.empty:\n",
    "        m = (by_group[\"level\"] == \"strategy_grade\") & (by_group[\"Adj Strategy\"] == s) & (by_group[\"Grade\"] == g)\n",
    "        if m.any():\n",
    "            row = by_group.loc[m].iloc[0].to_dict()\n",
    "    if row is None and not by_group.empty:\n",
    "        m = (by_group[\"level\"] == \"strategy\") & (by_group[\"Adj Strategy\"] == s)\n",
    "        if m.any():\n",
    "            row = by_group.loc[m].iloc[0].to_dict()\n",
    "    if row is None and global_row:\n",
    "        row = dict(global_row)\n",
    "        row[\"level\"] = \"global\"\n",
    "\n",
    "    if row:\n",
    "        row[\"Adj Strategy\"] = s\n",
    "        row[\"Grade\"] = g\n",
    "        row[\"AgeBucket\"] = a\n",
    "        selected_rows.append(row)\n",
    "\n",
    "selected = pd.DataFrame(selected_rows)\n",
    "selected.to_csv(Path(OUT_DIR) / \"timing_probs_selected.csv\", index=False)\n",
    "\n",
    "print(\"Wrote:\", Path(OUT_DIR) / \"timing_probs_by_group.csv\")\n",
    "print(\"Wrote:\", Path(OUT_DIR) / \"timing_probs_selected.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
