{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "738c448b",
   "metadata": {},
   "source": [
    "# Distribution Fits (Anonymized Data)\n",
    "\n",
    "This notebook fits candidate distributions for drawdown, repayment, and recallable ratios.\n",
    "It handles zeroâ€‘inflation by modeling a mass at 0 and fitting the positive tail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1b4f7c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-31T06:29:07.438752Z",
     "iopub.status.busy": "2026-01-31T06:29:07.437994Z",
     "iopub.status.idle": "2026-01-31T06:29:10.098821Z",
     "shell.execute_reply": "2026-01-31T06:29:10.096664Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scipy version: 1.17.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    import scipy\n",
    "    from scipy import stats\n",
    "    print(\"scipy version:\", scipy.__version__)\n",
    "except Exception as e:\n",
    "    raise ImportError(\"scipy is required for fitting: pip install scipy\") from e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "809dc58a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-31T06:29:10.104382Z",
     "iopub.status.busy": "2026-01-31T06:29:10.103833Z",
     "iopub.status.idle": "2026-01-31T06:29:10.114353Z",
     "shell.execute_reply": "2026-01-31T06:29:10.111121Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using INPUT_PATH: /Users/mozeramozali/Desktop/Equity-Cashflow-projection/anonymized.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "RUN_TAG = os.environ.get(\"RUN_TAG\")\n",
    "HIST_END = os.environ.get(\"HIST_END\")\n",
    "if RUN_TAG is None:\n",
    "    RUN_TAG = HIST_END or \"2025Q3\"\n",
    "BASE_OUT = Path(\"model_fits\") / \"runs\" / RUN_TAG\n",
    "CALIB_DIR = BASE_OUT / \"calibration\"\n",
    "PROJ_DIR = BASE_OUT / \"projection\"\n",
    "\n",
    "\n",
    "INPUT_PATH = \"/Users/mozeramozali/Desktop/Equity-Cashflow-projection/anonymized.csv\"\n",
    "OUT_DIR = str(CALIB_DIR)\n",
    "\n",
    "# Auto-detect anonymized.csv if not in current working directory\n",
    "if not Path(INPUT_PATH).exists():\n",
    "    candidates = list(Path.cwd().glob(\"**/anonymized.csv\"))\n",
    "    if candidates:\n",
    "        INPUT_PATH = str(candidates[0])\n",
    "    else:\n",
    "        raise FileNotFoundError(\"anonymized.csv not found. Set INPUT_PATH to the full path.\")\n",
    "\n",
    "print(\"Using INPUT_PATH:\", INPUT_PATH)\n",
    "Path(OUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "Path(CALIB_DIR).mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1913bc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-31T06:29:10.119295Z",
     "iopub.status.busy": "2026-01-31T06:29:10.118761Z",
     "iopub.status.idle": "2026-01-31T06:29:10.126480Z",
     "shell.execute_reply": "2026-01-31T06:29:10.125226Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Column normalization ---\n",
    "\n",
    "def _norm_key(s: str) -> str:\n",
    "    return \" \".join(s.strip().lower().replace(\"_\", \" \").split())\n",
    "\n",
    "def normalize_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    col_map = {_norm_key(c): c for c in df.columns}\n",
    "    def _get(name: str) -> str:\n",
    "        k = _norm_key(name)\n",
    "        return col_map.get(k, name)\n",
    "\n",
    "    rename = {}\n",
    "    rename[_get(\"Adj strategy\")] = \"Adj Strategy\"\n",
    "    rename[_get(\"Adj Strategy\")] = \"Adj Strategy\"\n",
    "    rename[_get(\"Quarter of Transaction Date\")] = \"Quarter\"\n",
    "    rename[_get(\"Year of Transaction Date\")] = \"Year\"\n",
    "    rename[_get(\"FundID\")] = \"FundID\"\n",
    "    rename[_get(\"First Closing Date\")] = \"First Closing Date\"\n",
    "    rename[_get(\"Grade\")] = \"Grade\"\n",
    "    rename[_get(\"Adj Drawdown EUR\")] = \"Adj Drawdown EUR\"\n",
    "    rename[_get(\"Adj Repayment EUR\")] = \"Adj Repayment EUR\"\n",
    "    rename[_get(\"NAV Adjusted EUR\")] = \"NAV Adjusted EUR\"\n",
    "    rename[_get(\"Capacity\")] = \"Capacity\"\n",
    "    rename[_get(\"Recallable\")] = \"Recallable\"\n",
    "    rename[_get(\"Fund_Age_Quarters\")] = \"Fund_Age_Quarters\"\n",
    "    rename[_get(\"Drawdown_Ratio\")] = \"Drawdown_Ratio\"\n",
    "    rename[_get(\"Repayment_Ratio\")] = \"Repayment_Ratio\"\n",
    "\n",
    "    return df.rename(columns=rename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a01877c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-31T06:29:10.130910Z",
     "iopub.status.busy": "2026-01-31T06:29:10.130323Z",
     "iopub.status.idle": "2026-01-31T06:29:10.891107Z",
     "shell.execute_reply": "2026-01-31T06:29:10.889631Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows 30857 cols 23\n"
     ]
    }
   ],
   "source": [
    "# --- Load data ---\n",
    "\n",
    "df = pd.read_csv(INPUT_PATH, engine=\"python\")\n",
    "df = normalize_columns(df)\n",
    "print(\"rows\", len(df), \"cols\", len(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16285e61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-31T06:29:10.896720Z",
     "iopub.status.busy": "2026-01-31T06:29:10.896261Z",
     "iopub.status.idle": "2026-01-31T06:29:43.159418Z",
     "shell.execute_reply": "2026-01-31T06:29:43.156083Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w3/y0xpfndx1099qx0947v35sxh0000gn/T/ipykernel_80529/3517830727.py:24: FutureWarning: Constructing PeriodIndex from fields is deprecated. Use PeriodIndex.from_fields instead.\n",
      "  df.loc[m, \"quarter_end\"] = pd.PeriodIndex(year=years, quarter=quarters, freq=\"Q\").to_timestamp(\"Q\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w3/y0xpfndx1099qx0947v35sxh0000gn/T/ipykernel_80529/3517830727.py:237: PerformanceWarning: Adding/subtracting object-dtype array to DatetimeArray not vectorized.\n",
      "  q_snap[\"FirstCloseDate\"] + q_snap[\"InvestPeriodYears\"].apply(lambda y: pd.DateOffset(years=int(y)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed Grade_Current using performance rules for distribution fits.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "draw_ratio n 30857 zero_share 0.09388469391061996 >1 share 0.0\n",
      "rep_ratio n 26365 zero_share 0.8258741938620087 >1 share 0.0\n",
      "rc_ratio_given_rep n 5417 zero_share 0.9461062319732961 >1 share 0.0070648475224422335\n"
     ]
    }
   ],
   "source": [
    "# --- Build quarter_end + ratios ---\n",
    "\n",
    "def parse_quarter(q):\n",
    "    if pd.isna(q):\n",
    "        return np.nan\n",
    "    if isinstance(q, (int, np.integer, float, np.floating)):\n",
    "        return float(q)\n",
    "    s = str(q).strip().upper()\n",
    "    if s.startswith(\"Q\"):\n",
    "        s = s[1:]\n",
    "    try:\n",
    "        return float(s)\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def add_quarter_end(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df[\"Quarter\"] = df[\"Quarter\"].apply(parse_quarter)\n",
    "    df[\"Year\"] = pd.to_numeric(df[\"Year\"], errors=\"coerce\")\n",
    "    m = df[\"Year\"].notna() & df[\"Quarter\"].notna()\n",
    "    years = df.loc[m, \"Year\"].astype(int)\n",
    "    quarters = df.loc[m, \"Quarter\"].astype(int)\n",
    "    df.loc[m, \"quarter_end\"] = pd.PeriodIndex(year=years, quarter=quarters, freq=\"Q\").to_timestamp(\"Q\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def apply_current_grade(df: pd.DataFrame, context: str = \"\") -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "\n",
    "    if \"Grade\" in df.columns and \"Grade_Seed\" not in df.columns:\n",
    "        df[\"Grade_Seed\"] = df[\"Grade\"]\n",
    "\n",
    "    if \"Grade\" in df.columns:\n",
    "        df[\"Grade\"] = df[\"Grade\"].astype(str).str.strip()\n",
    "        df.loc[df[\"Grade\"].isin([\"\", \"nan\", \"None\", \"NaN\", \"<NA>\"]), \"Grade\"] = np.nan\n",
    "\n",
    "    if \"quarter_end\" not in df.columns:\n",
    "        df = add_quarter_end(df)\n",
    "\n",
    "    df[\"QPeriod\"] = df[\"quarter_end\"].dt.to_period(\"Q\")\n",
    "\n",
    "    cols = [\n",
    "        \"FundID\",\n",
    "        \"Adj Strategy\",\n",
    "        \"QPeriod\",\n",
    "        \"quarter_end\",\n",
    "        \"Adj Drawdown EUR\",\n",
    "        \"Adj Repayment EUR\",\n",
    "        \"NAV Adjusted EUR\",\n",
    "        \"First Closing Date\",\n",
    "        \"Grade\",\n",
    "    ]\n",
    "    cols = [c for c in cols if c in df.columns]\n",
    "    cash = df[cols].copy()\n",
    "    cash = cash.rename(\n",
    "        columns={\n",
    "            \"Adj Strategy\": \"AdjStrategy\",\n",
    "            \"quarter_end\": \"TransactionDate\",\n",
    "            \"First Closing Date\": \"FirstClosingDate\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    cash[\"TransactionDate\"] = pd.to_datetime(cash[\"TransactionDate\"], errors=\"coerce\")\n",
    "    if \"FirstClosingDate\" in cash.columns:\n",
    "        cash[\"FirstClosingDate\"] = pd.to_datetime(cash[\"FirstClosingDate\"], errors=\"coerce\")\n",
    "    else:\n",
    "        cash[\"FirstClosingDate\"] = pd.NaT\n",
    "\n",
    "    for c in [\"Adj Drawdown EUR\", \"Adj Repayment EUR\", \"NAV Adjusted EUR\"]:\n",
    "        if c in cash.columns:\n",
    "            cash[c] = pd.to_numeric(cash[c], errors=\"coerce\").fillna(0.0)\n",
    "        else:\n",
    "            cash[c] = 0.0\n",
    "\n",
    "    cash = cash.dropna(subset=[\"FundID\", \"TransactionDate\"])\n",
    "\n",
    "    if cash[\"FirstClosingDate\"].isna().any():\n",
    "        first_tx = cash.groupby(\"FundID\")[\"TransactionDate\"].transform(\"min\")\n",
    "        cash[\"FirstClosingDate\"] = cash[\"FirstClosingDate\"].fillna(first_tx)\n",
    "\n",
    "    if cash.empty:\n",
    "        return df\n",
    "\n",
    "    fund_strategy = (\n",
    "        cash.groupby(\"FundID\")[\"AdjStrategy\"]\n",
    "        .agg(lambda s: s.mode().iat[0] if len(s.mode()) else s.iloc[0])\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    q_snap = (\n",
    "        cash.sort_values([\"FundID\", \"TransactionDate\"])\n",
    "        .groupby([\"FundID\", \"QPeriod\"], as_index=False)\n",
    "        .agg(\n",
    "            AdjStrategy=(\"AdjStrategy\", \"last\"),\n",
    "            FirstClosingDate=(\"FirstClosingDate\", \"last\"),\n",
    "            QuarterDrawdown=(\"Adj Drawdown EUR\", \"sum\"),\n",
    "            QuarterRepayment=(\"Adj Repayment EUR\", \"sum\"),\n",
    "            QuarterEndNAV=(\"NAV Adjusted EUR\", \"last\"),\n",
    "            QuarterEndDate=(\"TransactionDate\", \"max\"),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    q_snap = q_snap.sort_values([\"FundID\", \"QPeriod\"])\n",
    "    q_snap[\"QuarterEndNAV\"] = q_snap.groupby(\"FundID\")[\"QuarterEndNAV\"].ffill().fillna(0)\n",
    "\n",
    "    q_snap[\"CumDrawdown\"] = q_snap.groupby(\"FundID\")[\"QuarterDrawdown\"].cumsum()\n",
    "    q_snap[\"CumRepayment\"] = q_snap.groupby(\"FundID\")[\"QuarterRepayment\"].cumsum()\n",
    "    q_snap[\"PaidIn\"] = q_snap[\"CumDrawdown\"].abs()\n",
    "    q_snap[\"Distributed\"] = q_snap[\"CumRepayment\"].abs()\n",
    "    q_snap[\"NAV\"] = q_snap[\"QuarterEndNAV\"].abs()\n",
    "\n",
    "    q_snap[\"DPI\"] = np.where(q_snap[\"PaidIn\"] > 0, q_snap[\"Distributed\"] / q_snap[\"PaidIn\"], np.nan)\n",
    "    q_snap[\"TVPI\"] = np.where(\n",
    "        q_snap[\"PaidIn\"] > 0,\n",
    "        (q_snap[\"Distributed\"] + q_snap[\"NAV\"]) / q_snap[\"PaidIn\"],\n",
    "        np.nan,\n",
    "    )\n",
    "\n",
    "    def xnpv(rate, cfs, dts):\n",
    "        dts = np.asarray(dts, dtype=\"datetime64[ns]\")\n",
    "        cfs = np.asarray(cfs, dtype=float)\n",
    "        t0 = dts[0]\n",
    "        day_counts = (dts - t0) / np.timedelta64(1, \"D\")\n",
    "        years = day_counts / 365.0\n",
    "        return np.sum(cfs / ((1.0 + rate) ** years))\n",
    "\n",
    "    def xirr_newton(cfs, dts, guess=0.1, max_iter=80, tol=1e-7):\n",
    "        dts = np.asarray(dts, dtype=\"datetime64[ns]\")\n",
    "        cfs = np.asarray(cfs, dtype=float)\n",
    "        rate = float(guess)\n",
    "        for _ in range(max_iter):\n",
    "            f = xnpv(rate, cfs, dts)\n",
    "            if not np.isfinite(f):\n",
    "                return np.nan\n",
    "            if abs(f) < tol:\n",
    "                return rate\n",
    "            eps = 1e-6\n",
    "            f1 = xnpv(rate + eps, cfs, dts)\n",
    "            df = (f1 - f) / eps\n",
    "            if df == 0 or not np.isfinite(df):\n",
    "                return np.nan\n",
    "            rate_new = rate - f / df\n",
    "            if rate_new <= -0.999999 or not np.isfinite(rate_new):\n",
    "                return np.nan\n",
    "            rate = rate_new\n",
    "        return np.nan\n",
    "\n",
    "    def compute_fund_quarter_xirr(fund_cash, fund_q):\n",
    "        fund_cash = fund_cash.sort_values(\"TransactionDate\")\n",
    "        cfs = (-fund_cash[\"Adj Drawdown EUR\"].abs() + fund_cash[\"Adj Repayment EUR\"].abs()).to_numpy(dtype=float)\n",
    "        dts = fund_cash[\"TransactionDate\"].to_numpy(dtype=\"datetime64[ns]\")\n",
    "        irr_vals = []\n",
    "        irr_flags = []\n",
    "        j = 0\n",
    "        n = len(cfs)\n",
    "        for r in fund_q.itertuples(index=False):\n",
    "            q_end = np.datetime64(r.QuarterEndDate, \"ns\")\n",
    "            while j < n and dts[j] <= q_end:\n",
    "                j += 1\n",
    "            cfs_slice = cfs[:j]\n",
    "            dts_slice = dts[:j]\n",
    "            if len(cfs_slice) == 0:\n",
    "                irr_vals.append(np.nan)\n",
    "                irr_flags.append(\"no_txns\")\n",
    "                continue\n",
    "            terminal_nav = float(abs(r.NAV)) if np.isfinite(r.NAV) else 0.0\n",
    "            cfs_full = np.append(cfs_slice, terminal_nav)\n",
    "            dts_full = np.append(dts_slice, q_end).astype(\"datetime64[ns]\")\n",
    "            if not (np.any(cfs_full < 0) and np.any(cfs_full > 0)):\n",
    "                irr_vals.append(np.nan)\n",
    "                irr_flags.append(\"no_sign_change\")\n",
    "                continue\n",
    "            tvpi = r.TVPI\n",
    "            guess = 0.10 if (pd.notna(tvpi) and tvpi > 1.0) else -0.10\n",
    "            irr = xirr_newton(cfs_full, dts_full, guess=guess)\n",
    "            if pd.notna(tvpi) and (0.98 <= tvpi <= 1.02):\n",
    "                if not np.isfinite(irr):\n",
    "                    irr2 = xirr_newton(cfs_full, dts_full, guess=-guess)\n",
    "                    if np.isfinite(irr2):\n",
    "                        irr = irr2\n",
    "                        irr_flags.append(\"flat_retry_success\")\n",
    "                    else:\n",
    "                        irr = 0.0\n",
    "                        irr_flags.append(\"flat_to_zero\")\n",
    "                else:\n",
    "                    irr_flags.append(\"flat_success\")\n",
    "            else:\n",
    "                irr_flags.append(\"ok\" if np.isfinite(irr) else \"fail\")\n",
    "            irr_vals.append(irr)\n",
    "        return pd.DataFrame({\"IRR\": irr_vals, \"IRR_Flag\": irr_flags})\n",
    "\n",
    "    irr_rows = []\n",
    "    for fund_id, fund_q in q_snap.groupby(\"FundID\", sort=False):\n",
    "        fund_cash = cash[cash[\"FundID\"] == fund_id]\n",
    "        irr_df = compute_fund_quarter_xirr(fund_cash, fund_q)\n",
    "        irr_df = irr_df.copy()\n",
    "        irr_df[\"FundID\"] = fund_id\n",
    "        irr_df[\"QPeriod\"] = fund_q[\"QPeriod\"].values\n",
    "        irr_rows.append(irr_df)\n",
    "\n",
    "    if irr_rows:\n",
    "        irr_all = pd.concat(irr_rows, ignore_index=True)\n",
    "        q_snap = q_snap.merge(irr_all, on=[\"FundID\", \"QPeriod\"], how=\"left\")\n",
    "    else:\n",
    "        q_snap[\"IRR\"] = np.nan\n",
    "\n",
    "    def quartile_to_grade(s):\n",
    "        r = s.rank(pct=True)\n",
    "        return pd.cut(r, [0, 0.25, 0.5, 0.75, 1], labels=[\"D\", \"C\", \"B\", \"A\"], include_lowest=True)\n",
    "\n",
    "    q_snap[\"Grade_DPI\"] = q_snap.groupby([\"AdjStrategy\", \"QPeriod\"])[\"DPI\"].transform(quartile_to_grade)\n",
    "    q_snap[\"Grade_TVPI\"] = q_snap.groupby([\"AdjStrategy\", \"QPeriod\"])[\"TVPI\"].transform(quartile_to_grade)\n",
    "    q_snap[\"Grade_IRR\"] = q_snap.groupby([\"AdjStrategy\", \"QPeriod\"])[\"IRR\"].transform(quartile_to_grade)\n",
    "\n",
    "    DEBT_STRATEGIES = {\"Hybrid Debt-Equity\", \"Private Debt\", \"Other Private Debt\"}\n",
    "    VC_STRATEGY = \"Venture Capital\"\n",
    "\n",
    "    rep = cash[cash[\"Adj Repayment EUR\"].abs() > 0].copy()\n",
    "    first_repay = rep.groupby(\"FundID\")[\"TransactionDate\"].min().reset_index(name=\"FirstRepaymentDate\")\n",
    "    first_close = cash.groupby(\"FundID\")[\"FirstClosingDate\"].min().reset_index(name=\"FirstCloseDate\")\n",
    "    fund_timing = first_close.merge(first_repay, on=\"FundID\", how=\"left\")\n",
    "    fund_timing = fund_timing.merge(fund_strategy, on=\"FundID\", how=\"left\")\n",
    "    fund_timing[\"RepayWithin5Y\"] = (\n",
    "        fund_timing[\"FirstRepaymentDate\"].notna()\n",
    "        & (fund_timing[\"FirstRepaymentDate\"] <= (fund_timing[\"FirstCloseDate\"] + pd.DateOffset(years=5)))\n",
    "    )\n",
    "    fund_timing[\"BaseYears\"] = np.where(fund_timing[\"RepayWithin5Y\"], 5, 6)\n",
    "    fund_timing[\"InvestPeriodYears\"] = fund_timing[\"BaseYears\"] + 1\n",
    "\n",
    "    q_snap = q_snap.merge(\n",
    "        fund_timing[[\"FundID\", \"FirstCloseDate\", \"InvestPeriodYears\", \"AdjStrategy\"]],\n",
    "        on=[\"FundID\", \"AdjStrategy\"],\n",
    "        how=\"left\",\n",
    "    )\n",
    "    q_snap[\"IsInvestmentPeriod\"] = q_snap[\"QuarterEndDate\"] <= (\n",
    "        q_snap[\"FirstCloseDate\"] + q_snap[\"InvestPeriodYears\"].apply(lambda y: pd.DateOffset(years=int(y)))\n",
    "    )\n",
    "\n",
    "    fund_counts = (\n",
    "        q_snap.groupby([\"AdjStrategy\", \"QPeriod\"])[\"FundID\"].nunique().rename(\"StrategyFundCount\").reset_index()\n",
    "    )\n",
    "    q_snap = q_snap.merge(fund_counts, on=[\"AdjStrategy\", \"QPeriod\"], how=\"left\")\n",
    "\n",
    "    q_snap[\"IsDebt\"] = q_snap[\"AdjStrategy\"].isin(DEBT_STRATEGIES)\n",
    "    q_snap[\"IsVC\"] = q_snap[\"AdjStrategy\"].eq(VC_STRATEGY)\n",
    "\n",
    "    grade_to_idx = {\"A\": 0, \"B\": 1, \"C\": 2, \"D\": 3}\n",
    "    idx_to_grade = {0: \"A\", 1: \"B\", 2: \"C\", 3: \"D\"}\n",
    "\n",
    "    def worse_grade(g1, g2):\n",
    "        if pd.isna(g1):\n",
    "            return g2\n",
    "        if pd.isna(g2):\n",
    "            return g1\n",
    "        return g1 if grade_to_idx[g1] >= grade_to_idx[g2] else g2\n",
    "\n",
    "    def downgrade_one_notch(g):\n",
    "        if pd.isna(g):\n",
    "            return g\n",
    "        return idx_to_grade[min(grade_to_idx[g] + 1, 3)]\n",
    "\n",
    "    def final_grade(row):\n",
    "        if row[\"StrategyFundCount\"] < 30:\n",
    "            return worse_grade(row[\"Grade_DPI\"], row[\"Grade_TVPI\"])\n",
    "        if row[\"IsDebt\"]:\n",
    "            return row[\"Grade_IRR\"]\n",
    "        if row[\"IsInvestmentPeriod\"]:\n",
    "            return row[\"Grade_TVPI\"] if row[\"IsVC\"] else row[\"Grade_DPI\"]\n",
    "        base = row[\"Grade_IRR\"]\n",
    "        dpi_g = row[\"Grade_DPI\"]\n",
    "        if pd.isna(base):\n",
    "            return base\n",
    "        if pd.notna(dpi_g) and (grade_to_idx[dpi_g] > grade_to_idx[base]):\n",
    "            return downgrade_one_notch(base)\n",
    "        return base\n",
    "\n",
    "    q_snap[\"CurrentGrade\"] = q_snap.apply(final_grade, axis=1)\n",
    "\n",
    "    fund_quarters = cash[[\"FundID\", \"QPeriod\"]].drop_duplicates().sort_values([\"FundID\", \"QPeriod\"])\n",
    "    fund_quarters[\"RankQ\"] = fund_quarters.groupby(\"FundID\").cumcount() + 1\n",
    "    fund_quarters[\"Block4\"] = (fund_quarters[\"RankQ\"] - 1) // 4 + 1\n",
    "\n",
    "    fund_first = (\n",
    "        cash.dropna(subset=[\"Grade\"]).groupby(\"FundID\", as_index=False).first()[[\"FundID\", \"Grade\"]]\n",
    "        .rename(columns={\"Grade\": \"FirstGrade\"})\n",
    "    )\n",
    "\n",
    "    fund_quarters = fund_quarters.merge(fund_first, on=\"FundID\", how=\"left\")\n",
    "    fund_quarters = fund_quarters.merge(\n",
    "        q_snap[[\"FundID\", \"QPeriod\", \"CurrentGrade\"]], on=[\"FundID\", \"QPeriod\"], how=\"left\"\n",
    "    )\n",
    "\n",
    "    fund_quarters[\"AssignedGrade\"] = np.where(\n",
    "        (fund_quarters[\"RankQ\"] <= 20) & fund_quarters[\"FirstGrade\"].notna(),\n",
    "        fund_quarters[\"FirstGrade\"],\n",
    "        fund_quarters[\"CurrentGrade\"],\n",
    "    )\n",
    "\n",
    "    fund_quarters[\"AssignedGrade\"] = fund_quarters.groupby(\"FundID\")[\"AssignedGrade\"].ffill()\n",
    "\n",
    "    df = df.merge(fund_quarters[[\"FundID\", \"QPeriod\", \"AssignedGrade\"]], on=[\"FundID\", \"QPeriod\"], how=\"left\")\n",
    "    df[\"Grade_Current\"] = df[\"AssignedGrade\"]\n",
    "    if \"Grade_Seed\" in df.columns:\n",
    "        df[\"Grade_Current\"] = df[\"Grade_Current\"].fillna(df[\"Grade_Seed\"])\n",
    "    df[\"Grade\"] = df[\"Grade_Current\"]\n",
    "\n",
    "    if context:\n",
    "        print(f\"Computed Grade_Current using performance rules for {context}.\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Build quarter_end + grade history\n",
    "\n",
    "df = add_quarter_end(df)\n",
    "df = df.dropna(subset=[\"quarter_end\"])\n",
    "df = apply_current_grade(df, context=\"distribution fits\")\n",
    "\n",
    "# ratios\n",
    "\n",
    "df = df.sort_values([\"FundID\", \"quarter_end\"])\n",
    "df[\"nav_prev\"] = df.groupby(\"FundID\")[\"NAV Adjusted EUR\"].shift(1)\n",
    "\n",
    "# fund-level commitment (Commitment EUR only)\n",
    "comm = pd.to_numeric(df.get(\"Commitment EUR\"), errors=\"coerce\")\n",
    "commit = comm.groupby(df[\"FundID\"]).transform(\"max\")\n",
    "draw = pd.to_numeric(df[\"Adj Drawdown EUR\"], errors=\"coerce\").abs()\n",
    "draw_cum = df.groupby(\"FundID\")[\"Adj Drawdown EUR\"].transform(lambda s: s.abs().cumsum())\n",
    "rep = pd.to_numeric(df[\"Adj Repayment EUR\"], errors=\"coerce\")\n",
    "nav_prev = pd.to_numeric(df[\"nav_prev\"], errors=\"coerce\")\n",
    "rc = pd.to_numeric(df[\"Recallable\"], errors=\"coerce\").abs()\n",
    "rc_cum = df.groupby(\"FundID\")[\"Recallable\"].transform(lambda s: pd.to_numeric(s, errors=\"coerce\").abs().cumsum())\n",
    "\n",
    "denom = commit + rc_cum\n",
    "\n",
    "# computed ratios\n",
    "\n",
    "df[\"draw_ratio_calc\"] = np.where(denom > 0, draw_cum / denom, np.nan)\n",
    "df[\"draw_ratio_calc\"] = df[\"draw_ratio_calc\"].clip(lower=0.0, upper=1.0)\n",
    "df[\"rep_ratio_calc\"] = np.where(nav_prev.abs() > 1.0, rep / nav_prev.abs(), np.nan)\n",
    "df[\"rc_ratio_given_rep\"] = np.where(rep > 0, rc / rep, np.nan)\n",
    "\n",
    "AGE_BINS_Q = [-1, 3, 7, 11, 15, 19, 1000]\n",
    "AGE_LABELS = [\"0-3\", \"4-7\", \"8-11\", \"12-15\", \"16-19\", \"20+\"]\n",
    "if \"Fund_Age_Quarters\" in df.columns:\n",
    "    df[\"AgeBucket\"] = pd.cut(pd.to_numeric(df[\"Fund_Age_Quarters\"], errors=\"coerce\"),\n",
    "                              bins=AGE_BINS_Q, labels=AGE_LABELS)\n",
    "else:\n",
    "    df[\"AgeBucket\"] = \"ALL\"\n",
    "\n",
    "ratio_map = {\n",
    "    \"draw_ratio\": df[\"draw_ratio_calc\"],\n",
    "    \"rep_ratio\": df[\"rep_ratio_calc\"],\n",
    "    \"rc_ratio_given_rep\": df[\"rc_ratio_given_rep\"],\n",
    "}\n",
    "\n",
    "for name, s in ratio_map.items():\n",
    "    s = pd.to_numeric(s, errors=\"coerce\")\n",
    "    print(name, \"n\", s.notna().sum(), \"zero_share\", (s.fillna(0) <= 1e-9).mean(),\n",
    "          \">1 share\", (s > 1).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f38a7b25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-31T06:29:43.163442Z",
     "iopub.status.busy": "2026-01-31T06:29:43.163075Z",
     "iopub.status.idle": "2026-01-31T06:29:43.185194Z",
     "shell.execute_reply": "2026-01-31T06:29:43.183617Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Fit distributions ---\n",
    "\n",
    "def _fit_dist(x: np.ndarray, dist_name: str):\n",
    "    dist = getattr(stats, dist_name)\n",
    "    if dist_name in (\"beta\", \"logitnorm\"):\n",
    "        params = dist.fit(x, floc=0, fscale=1)\n",
    "    elif dist_name in (\"lognorm\", \"gamma\", \"weibull_min\", \"fisk\"):\n",
    "        params = dist.fit(x, floc=0)\n",
    "    else:\n",
    "        params = dist.fit(x)\n",
    "    ll = float(np.sum(dist.logpdf(x, *params)))\n",
    "    k = len(params)\n",
    "    return params, ll, k\n",
    "\n",
    "# estimate mean by sampling (used for scaling/capping)\n",
    "def _estimate_mean(dist_name: str, params, n=5000, cap=None, seed=42):\n",
    "    try:\n",
    "        dist = getattr(stats, dist_name)\n",
    "        rng = np.random.default_rng(seed)\n",
    "        samp = dist.rvs(*params, size=n, random_state=rng)\n",
    "        samp = np.asarray(samp, dtype=float)\n",
    "        samp = samp[np.isfinite(samp)]\n",
    "        if cap is not None:\n",
    "            samp = np.clip(samp, 0.0, cap)\n",
    "        return float(np.mean(samp)) if len(samp) else float(\"nan\")\n",
    "    except Exception:\n",
    "        return float(\"nan\")\n",
    "\n",
    "\n",
    "\n",
    "def _ks_pvalue(x: np.ndarray, dist_name: str, params):\n",
    "    try:\n",
    "        d, p = stats.kstest(x, dist_name, args=params)\n",
    "        return float(p)\n",
    "    except Exception:\n",
    "        return float(\"nan\")\n",
    "\n",
    "\n",
    "def fit_candidates(x: np.ndarray, dist_names, eps=1e-9, cap=None):\n",
    "    rows = []\n",
    "    for name in dist_names:\n",
    "        try:\n",
    "            if name in (\"beta\", \"logitnorm\"):\n",
    "                x_fit = x[(x > eps) & (x < 1.0 - eps)]\n",
    "            else:\n",
    "                x_fit = x\n",
    "            n_fit = len(x_fit)\n",
    "            if n_fit == 0:\n",
    "                rows.append({\"dist\": name, \"aic\": np.nan, \"bic\": np.nan, \"ks_p\": np.nan, \"n_fit\": 0, \"params\": \"no_data\", \"mean_raw\": np.nan, \"mean_cap\": np.nan, \"median_raw\": np.nan, \"median_cap\": np.nan, \"cap_used\": cap})\n",
    "                continue\n",
    "            params, ll, k = _fit_dist(x_fit, name)\n",
    "            mean_raw = _estimate_mean(name, params, n=5000, cap=None)\n",
    "            mean_cap = _estimate_mean(name, params, n=5000, cap=cap)\n",
    "            median_raw = float(np.nanmedian(stats.__getattribute__(name).rvs(*params, size=2000, random_state=np.random.default_rng(123)))) if np.isfinite(mean_raw) else float(\"nan\")\n",
    "            median_cap = float(np.nanmedian(np.clip(stats.__getattribute__(name).rvs(*params, size=2000, random_state=np.random.default_rng(124)), 0.0, cap))) if cap is not None else float(\"nan\")\n",
    "            aic = 2 * k - 2 * ll\n",
    "            bic = np.log(n_fit) * k - 2 * ll\n",
    "            ks_p = _ks_pvalue(x_fit, name, params)\n",
    "            rows.append({\"dist\": name, \"aic\": aic, \"bic\": bic, \"ks_p\": ks_p, \"n_fit\": n_fit, \"params\": params, \"mean_raw\": mean_raw, \"mean_cap\": mean_cap, \"median_raw\": median_raw, \"median_cap\": median_cap, \"cap_used\": cap})\n",
    "        except Exception as e:\n",
    "            rows.append({\"dist\": name, \"aic\": np.nan, \"bic\": np.nan, \"ks_p\": np.nan, \"n_fit\": 0, \"params\": f\"error: {e}\", \"mean_raw\": np.nan, \"mean_cap\": np.nan, \"median_raw\": np.nan, \"median_cap\": np.nan, \"cap_used\": cap})\n",
    "    return rows\n",
    "\n",
    "\n",
    "def fit_ratio_series(x: pd.Series, dist_names, eps=1e-9, cap=None):\n",
    "    x = pd.to_numeric(x, errors=\"coerce\").dropna().clip(lower=0.0)\n",
    "    n = len(x)\n",
    "    n_zero = int((x <= eps).sum())\n",
    "    x_pos = x[x > eps].to_numpy(dtype=float)\n",
    "    zero_share = n_zero / float(n) if n else np.nan\n",
    "    data_mean = float(np.nanmean(x_pos)) if len(x_pos) else float(\"nan\")\n",
    "    data_median = float(np.nanmedian(x_pos)) if len(x_pos) else float(\"nan\")\n",
    "    data_p90 = float(np.nanquantile(x_pos, 0.9)) if len(x_pos) else float(\"nan\")\n",
    "    cap_used = cap if cap is not None else data_p90\n",
    "    fits = fit_candidates(x_pos, dist_names, eps=eps, cap=cap_used)\n",
    "    return {\"n\": n, \"n_pos\": len(x_pos), \"zero_share\": zero_share, \"fits\": fits, \"data_mean\": data_mean, \"data_median\": data_median, \"data_p90\": data_p90, \"cap_used\": cap_used}\n",
    "\n",
    "\n",
    "dist_names = [\"beta\", \"logitnorm\", \"lognorm\", \"gamma\", \"weibull_min\", \"fisk\"]\n",
    "dist_names_map = {\n",
    "    \"draw_ratio\": dist_names,\n",
    "    \"rep_ratio\": dist_names,\n",
    "    \"rc_ratio_given_rep\": dist_names,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a87b704",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-31T06:29:43.190675Z",
     "iopub.status.busy": "2026-01-31T06:29:43.190069Z",
     "iopub.status.idle": "2026-01-31T06:29:44.137037Z",
     "shell.execute_reply": "2026-01-31T06:29:44.135460Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 ratio      n  n_pos  zero_share  data_mean  data_median  \\\n",
      "0           draw_ratio  30857  27960    0.093885   0.627514     0.712442   \n",
      "4           draw_ratio  30857  27960    0.093885   0.627514     0.712442   \n",
      "3           draw_ratio  30857  27960    0.093885   0.627514     0.712442   \n",
      "5           draw_ratio  30857  27960    0.093885   0.627514     0.712442   \n",
      "2           draw_ratio  30857  27960    0.093885   0.627514     0.712442   \n",
      "1           draw_ratio  30857  27960    0.093885   0.627514     0.712442   \n",
      "12  rc_ratio_given_rep   5417   1663    0.693004   2.812229     0.720000   \n",
      "17  rc_ratio_given_rep   5417   1663    0.693004   2.812229     0.720000   \n",
      "16  rc_ratio_given_rep   5417   1663    0.693004   2.812229     0.720000   \n",
      "14  rc_ratio_given_rep   5417   1663    0.693004   2.812229     0.720000   \n",
      "\n",
      "    data_p90  cap_used         dist           aic           bic          ks_p  \\\n",
      "0   1.000000       1.0         beta  -1746.428682  -1714.052416  4.253547e-47   \n",
      "4   1.000000       1.0  weibull_min  20202.497341  20227.212932  0.000000e+00   \n",
      "3   1.000000       1.0        gamma  24848.988639  24873.704230  0.000000e+00   \n",
      "5   1.000000       1.0         fisk  31896.465781  31921.181372  0.000000e+00   \n",
      "2   1.000000       1.0      lognorm  42660.003180  42684.718771  0.000000e+00   \n",
      "1   1.000000       1.0    logitnorm           NaN           NaN           NaN   \n",
      "12  1.140982       1.0         beta   -449.446774   -429.859996  1.239777e-02   \n",
      "17  1.140982       1.0         fisk   3454.787764   3471.036900  3.202235e-59   \n",
      "16  1.140982       1.0  weibull_min   3831.754646   3848.003782  5.784943e-89   \n",
      "14  1.140982       1.0      lognorm   3921.726749   3937.975884  3.146024e-66   \n",
      "\n",
      "    n_fit                                             params  mean_raw  \\\n",
      "0   24199     (0.9340561622135813, 0.7463689377272109, 0, 1)  0.555312   \n",
      "4   27960        (1.7800730703764458, 0, 0.6905497075699342)  0.610650   \n",
      "3   27960         (1.8198795166981239, 0, 0.344810500094413)  0.629048   \n",
      "5   27960          (2.062362800843956, 0, 0.565069541444396)  0.862332   \n",
      "2   27960       (1.1152186752708388, 0, 0.46523122310519666)  0.848610   \n",
      "1       0  error: module 'scipy.stats' has no attribute '...       NaN   \n",
      "12    989     (0.5372709877819806, 0.9789188636779305, 0, 1)  0.352776   \n",
      "17   1663        (1.090031130708908, 0, 0.47783720159899656)  2.957507   \n",
      "16   1663        (0.5468804058600724, 0, 0.9330006683408452)  1.607210   \n",
      "14   1663        (1.9641299827029446, 0, 0.3998443945496849)  2.617650   \n",
      "\n",
      "    mean_cap  median_raw  median_cap  \n",
      "0   0.555312    0.577347    0.573680  \n",
      "4   0.574352    0.551800    0.569982  \n",
      "3   0.556048    0.510142    0.525417  \n",
      "5   0.592794    0.552822    0.574663  \n",
      "2   0.529157    0.476380    0.476036  \n",
      "1        NaN         NaN         NaN  \n",
      "12  0.352776    0.269022    0.280941  \n",
      "17  0.533536    0.458431    0.493302  \n",
      "16  0.520551    0.449579    0.499614  \n",
      "14  0.499769    0.416874    0.416344  \n",
      "Wrote model_fits/runs/2025Q3/calibration/ratio_fit_global.csv\n"
     ]
    }
   ],
   "source": [
    "# --- Global fits ---\n",
    "\n",
    "global_rows = []\n",
    "for name, series in ratio_map.items():\n",
    "    cap = 1.0 if name in (\"draw_ratio\", \"rc_ratio_given_rep\") else None\n",
    "    res = fit_ratio_series(series, dist_names_map.get(name, []), eps=1e-9, cap=cap)\n",
    "    for f in res[\"fits\"]:\n",
    "        global_rows.append({\n",
    "            \"ratio\": name,\n",
    "            \"n\": res[\"n\"],\n",
    "            \"n_pos\": res[\"n_pos\"],\n",
    "            \"zero_share\": res[\"zero_share\"],\n",
    "            \"data_mean\": res.get(\"data_mean\"),\n",
    "            \"data_median\": res.get(\"data_median\"),\n",
    "            \"data_p90\": res.get(\"data_p90\"),\n",
    "            \"cap_used\": res.get(\"cap_used\"),\n",
    "            **f,\n",
    "        })\n",
    "\n",
    "global_df = pd.DataFrame(global_rows).sort_values([\"ratio\", \"aic\"])\n",
    "print(global_df.head(10))\n",
    "\n",
    "out_global = os.path.join(OUT_DIR, \"ratio_fit_global.csv\")\n",
    "global_df.to_csv(out_global, index=False)\n",
    "print(\"Wrote\", out_global)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e33d63cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-31T06:29:44.143912Z",
     "iopub.status.busy": "2026-01-31T06:29:44.143455Z",
     "iopub.status.idle": "2026-01-31T06:30:02.518523Z",
     "shell.execute_reply": "2026-01-31T06:30:02.517450Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w3/y0xpfndx1099qx0947v35sxh0000gn/T/ipykernel_80529/2221806418.py:9: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for gkey, g in df.groupby(cols):\n",
      "/opt/miniconda3/lib/python3.12/site-packages/scipy/stats/_continuous_distns.py:905: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  fac = xbar * (1 - xbar) / data.var(ddof=0) - 1\n",
      "/opt/miniconda3/lib/python3.12/site-packages/scipy/stats/_continuous_distns.py:703: RuntimeWarning: invalid value encountered in scalar add\n",
      "  func = [s1 - n * (-psiab + sc.psi(a)),\n",
      "/opt/miniconda3/lib/python3.12/site-packages/scipy/stats/_continuous_distns.py:704: RuntimeWarning: invalid value encountered in scalar add\n",
      "  s2 - n * (-psiab + sc.psi(b))]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/scipy/stats/_continuous_distns.py:3748: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  aest = (3-s + np.sqrt((s-3)**2 + 24*s)) / (12*s)\n",
      "/opt/miniconda3/lib/python3.12/site-packages/scipy/stats/_continuous_distns.py:3751: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  a = optimize.brentq(lambda a: np.log(a) - sc.digamma(a) - s,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/scipy/stats/_continuous_distns.py:3748: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  aest = (3-s + np.sqrt((s-3)**2 + 24*s)) / (12*s)\n",
      "/opt/miniconda3/lib/python3.12/site-packages/scipy/stats/_continuous_distns.py:3751: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  a = optimize.brentq(lambda a: np.log(a) - sc.digamma(a) - s,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/scipy/stats/_continuous_distns.py:905: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  fac = xbar * (1 - xbar) / data.var(ddof=0) - 1\n",
      "/opt/miniconda3/lib/python3.12/site-packages/scipy/stats/_continuous_distns.py:703: RuntimeWarning: invalid value encountered in scalar add\n",
      "  func = [s1 - n * (-psiab + sc.psi(a)),\n",
      "/opt/miniconda3/lib/python3.12/site-packages/scipy/stats/_continuous_distns.py:704: RuntimeWarning: invalid value encountered in scalar add\n",
      "  s2 - n * (-psiab + sc.psi(b))]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/scipy/stats/_continuous_distns.py:3748: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  aest = (3-s + np.sqrt((s-3)**2 + 24*s)) / (12*s)\n",
      "/opt/miniconda3/lib/python3.12/site-packages/scipy/stats/_continuous_distns.py:3751: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  a = optimize.brentq(lambda a: np.log(a) - sc.digamma(a) - s,\n",
      "/opt/miniconda3/lib/python3.12/site-packages/scipy/stats/_continuous_distns.py:2824: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  s = stats.skew(data)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/scipy/stats/_continuous_distns.py:905: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  fac = xbar * (1 - xbar) / data.var(ddof=0) - 1\n",
      "/opt/miniconda3/lib/python3.12/site-packages/scipy/stats/_continuous_distns.py:703: RuntimeWarning: invalid value encountered in scalar add\n",
      "  func = [s1 - n * (-psiab + sc.psi(a)),\n",
      "/opt/miniconda3/lib/python3.12/site-packages/scipy/stats/_continuous_distns.py:704: RuntimeWarning: invalid value encountered in scalar add\n",
      "  s2 - n * (-psiab + sc.psi(b))]\n",
      "/opt/miniconda3/lib/python3.12/site-packages/scipy/stats/_continuous_distns.py:3748: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  aest = (3-s + np.sqrt((s-3)**2 + 24*s)) / (12*s)\n",
      "/opt/miniconda3/lib/python3.12/site-packages/scipy/stats/_continuous_distns.py:3751: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  a = optimize.brentq(lambda a: np.log(a) - sc.digamma(a) - s,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/scipy/stats/_continuous_distns.py:905: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  fac = xbar * (1 - xbar) / data.var(ddof=0) - 1\n",
      "/opt/miniconda3/lib/python3.12/site-packages/scipy/stats/_continuous_distns.py:703: RuntimeWarning: invalid value encountered in scalar add\n",
      "  func = [s1 - n * (-psiab + sc.psi(a)),\n",
      "/opt/miniconda3/lib/python3.12/site-packages/scipy/stats/_continuous_distns.py:704: RuntimeWarning: invalid value encountered in scalar add\n",
      "  s2 - n * (-psiab + sc.psi(b))]\n",
      "/opt/miniconda3/lib/python3.12/site-packages/scipy/stats/_continuous_distns.py:3748: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  aest = (3-s + np.sqrt((s-3)**2 + 24*s)) / (12*s)\n",
      "/opt/miniconda3/lib/python3.12/site-packages/scipy/stats/_continuous_distns.py:3751: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  a = optimize.brentq(lambda a: np.log(a) - sc.digamma(a) - s,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                ratio               level  group_n    n  n_pos  zero_share  \\\n",
      "0          draw_ratio  strategy_grade_age      195  195    195    0.000000   \n",
      "1           rep_ratio  strategy_grade_age      195  190     30    0.842105   \n",
      "2  rc_ratio_given_rep  strategy_grade_age      195   30      1    0.966667   \n",
      "3          draw_ratio  strategy_grade_age      214  214    214    0.000000   \n",
      "4           rep_ratio  strategy_grade_age      214  202     21    0.896040   \n",
      "5  rc_ratio_given_rep  strategy_grade_age      214   21      0    1.000000   \n",
      "6          draw_ratio  strategy_grade_age      235  235    235    0.000000   \n",
      "7           rep_ratio  strategy_grade_age      235  206      8    0.961165   \n",
      "8  rc_ratio_given_rep  strategy_grade_age      235    8      0    1.000000   \n",
      "9          draw_ratio  strategy_grade_age      220  220    220    0.000000   \n",
      "\n",
      "   data_mean  data_median  data_p90  cap_used  ...      ks_p  n_fit  \\\n",
      "0   0.691001     0.779477  1.000000  1.000000  ...  0.000026    122   \n",
      "1   0.030684     0.013614  0.059047  0.006598  ...  0.973725     30   \n",
      "2   0.951246     0.951246  0.951246  1.000000  ...  1.000000      1   \n",
      "3   0.699603     0.741960  1.000000  1.000000  ...  0.000001    163   \n",
      "4   0.076216     0.006405  0.270178  0.000216  ...  0.954731     21   \n",
      "5        NaN          NaN       NaN  1.000000  ...       NaN      0   \n",
      "6   0.526085     0.624012  0.892998  1.000000  ...  0.000009    213   \n",
      "7   0.119650     0.041368  0.301996  0.000000  ...  0.967159      8   \n",
      "8        NaN          NaN       NaN  1.000000  ...       NaN      0   \n",
      "9   0.844462     0.857566  1.000000  1.000000  ...  0.000006    194   \n",
      "\n",
      "                                           params  mean_raw  mean_cap  \\\n",
      "0   (2.036050667678798, 1.9458110420991117, 0, 1)  0.512309  0.512309   \n",
      "1   (0.6664162441417881, 0, 0.022295124785387317)  0.029563  0.005052   \n",
      "2  (1.204791959560528e-16, 0, 0.9512459577534289)  0.951246  0.951246   \n",
      "3  (1.2872279745790332, 1.0070838325433609, 0, 1)  0.557297  0.557297   \n",
      "4   (2.0695684044950906, 0, 0.009324462051942189)  0.074819  0.000212   \n",
      "5                                         no_data       NaN       NaN   \n",
      "6   (1.019089453166763, 1.2643549753730914, 0, 1)  0.453906  0.453906   \n",
      "7    (1.5238827100938903, 0, 0.04649089206157896)  0.144232  0.000000   \n",
      "8                                         no_data       NaN       NaN   \n",
      "9   (4.561793405031844, 0.9791449845539205, 0, 1)  0.826177  0.826177   \n",
      "\n",
      "  median_raw  median_cap        Adj Strategy  Grade  AgeBucket  \n",
      "0   0.514962    0.507692     Business Angels      B        20+  \n",
      "1   0.012246    0.006598     Business Angels      B        20+  \n",
      "2   0.951246    0.951246     Business Angels      B        20+  \n",
      "3   0.578540    0.583180     Business Angels      C        20+  \n",
      "4   0.009743    0.000216     Business Angels      C        20+  \n",
      "5        NaN         NaN     Business Angels      C        20+  \n",
      "6   0.425775    0.433098     Business Angels      D        20+  \n",
      "7   0.048020    0.000000     Business Angels      D        20+  \n",
      "8        NaN         NaN     Business Angels      D        20+  \n",
      "9   0.868660    0.864147  Hybrid Debt-Equity      A        20+  \n",
      "\n",
      "[10 rows x 23 columns]\n",
      "Wrote model_fits/runs/2025Q3/calibration/ratio_fit_by_group.csv\n"
     ]
    }
   ],
   "source": [
    "# --- Grouped fits (with fallback levels) ---\n",
    "\n",
    "MIN_OBS_AGE = 150\n",
    "MIN_OBS_SG = 200\n",
    "MIN_OBS_S = 300\n",
    "\n",
    "def _fit_level(level_name: str, cols: list, min_obs: int):\n",
    "    rows = []\n",
    "    for gkey, g in df.groupby(cols):\n",
    "        if not isinstance(gkey, tuple):\n",
    "            gkey = (gkey,)\n",
    "        if len(g) < min_obs:\n",
    "            continue\n",
    "        for name, series in [(\"draw_ratio\", g[\"draw_ratio_calc\"]),\n",
    "                             (\"rep_ratio\", g[\"rep_ratio_calc\"]),\n",
    "                             (\"rc_ratio_given_rep\", g[\"rc_ratio_given_rep\"])]:\n",
    "            cap = 1.0 if name in (\"draw_ratio\", \"rc_ratio_given_rep\") else float(pd.to_numeric(series, errors=\"coerce\").dropna().quantile(0.9)) if series.notna().any() else None\n",
    "            res = fit_ratio_series(series, dist_names_map.get(name, []), eps=1e-9, cap=cap)\n",
    "            if not res[\"fits\"]:\n",
    "                continue\n",
    "            best = sorted(res[\"fits\"], key=lambda r: (np.nan_to_num(r[\"aic\"], nan=np.inf)))[0]\n",
    "            row = {\n",
    "                \"ratio\": name,\n",
    "                \"level\": level_name,\n",
    "                \"group_n\": len(g),\n",
    "                \"n\": res[\"n\"],\n",
    "                \"n_pos\": res[\"n_pos\"],\n",
    "                \"zero_share\": res[\"zero_share\"],\n",
    "                \"data_mean\": res.get(\"data_mean\"),\n",
    "                \"data_median\": res.get(\"data_median\"),\n",
    "                \"data_p90\": res.get(\"data_p90\"),\n",
    "                \"cap_used\": res.get(\"cap_used\"),\n",
    "                **best,\n",
    "            }\n",
    "            for idx, col in enumerate(cols):\n",
    "                row[col] = gkey[idx]\n",
    "            rows.append(row)\n",
    "    return rows\n",
    "\n",
    "lvl_age = _fit_level(\"strategy_grade_age\", [\"Adj Strategy\", \"Grade\", \"AgeBucket\"], MIN_OBS_AGE)\n",
    "lvl_sg = _fit_level(\"strategy_grade\", [\"Adj Strategy\", \"Grade\"], MIN_OBS_SG)\n",
    "lvl_s = _fit_level(\"strategy\", [\"Adj Strategy\"], MIN_OBS_S)\n",
    "\n",
    "by_group = pd.DataFrame(lvl_age + lvl_sg + lvl_s)\n",
    "print(by_group.head(10))\n",
    "\n",
    "out_group = os.path.join(OUT_DIR, \"ratio_fit_by_group.csv\")\n",
    "by_group.to_csv(out_group, index=False)\n",
    "print(\"Wrote\", out_group)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79b33a5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-31T06:30:02.522524Z",
     "iopub.status.busy": "2026-01-31T06:30:02.522148Z",
     "iopub.status.idle": "2026-01-31T06:30:03.873331Z",
     "shell.execute_reply": "2026-01-31T06:30:03.871770Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote model_fits/runs/2025Q3/calibration/ratio_fit_selected.csv\n"
     ]
    }
   ],
   "source": [
    "# --- Selected with fallback ---\n",
    "\n",
    "best_global = (global_df.sort_values([\"ratio\", \"aic\"])\n",
    "               .groupby(\"ratio\").head(1)\n",
    "               .set_index(\"ratio\"))\n",
    "\n",
    "base_groups = df[[\"Adj Strategy\", \"Grade\", \"AgeBucket\"]].dropna().drop_duplicates()\n",
    "selected_rows = []\n",
    "\n",
    "for _, r in base_groups.iterrows():\n",
    "    s, g, a = r[\"Adj Strategy\"], r[\"Grade\"], r[\"AgeBucket\"]\n",
    "    for ratio in [\"draw_ratio\", \"rep_ratio\", \"rc_ratio_given_rep\"]:\n",
    "        row = None\n",
    "        if not by_group.empty:\n",
    "            m = (by_group[\"ratio\"] == ratio) & (by_group[\"level\"] == \"strategy_grade_age\") & \\\n",
    "                (by_group[\"Adj Strategy\"] == s) & (by_group[\"Grade\"] == g) & (by_group[\"AgeBucket\"] == a)\n",
    "            if m.any():\n",
    "                row = by_group.loc[m].iloc[0].to_dict()\n",
    "        if row is None and not by_group.empty:\n",
    "            m = (by_group[\"ratio\"] == ratio) & (by_group[\"level\"] == \"strategy_grade\") & \\\n",
    "                (by_group[\"Adj Strategy\"] == s) & (by_group[\"Grade\"] == g)\n",
    "            if m.any():\n",
    "                row = by_group.loc[m].iloc[0].to_dict()\n",
    "        if row is None and not by_group.empty:\n",
    "            m = (by_group[\"ratio\"] == ratio) & (by_group[\"level\"] == \"strategy\") & \\\n",
    "                (by_group[\"Adj Strategy\"] == s)\n",
    "            if m.any():\n",
    "                row = by_group.loc[m].iloc[0].to_dict()\n",
    "        if row is None and ratio in best_global.index:\n",
    "            row = best_global.loc[ratio].to_dict()\n",
    "            row[\"level\"] = \"global\"\n",
    "        if row is None:\n",
    "            continue\n",
    "        row[\"Adj Strategy\"] = s\n",
    "        row[\"Grade\"] = g\n",
    "        row[\"AgeBucket\"] = a\n",
    "        selected_rows.append(row)\n",
    "\n",
    "selected = pd.DataFrame(selected_rows)\n",
    "out_sel = os.path.join(OUT_DIR, \"ratio_fit_selected.csv\")\n",
    "selected.to_csv(out_sel, index=False)\n",
    "print(\"Wrote\", out_sel)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
